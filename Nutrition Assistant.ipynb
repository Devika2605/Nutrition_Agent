{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n# Agents Lab Notebook v1.0.0\nThis notebook contains steps and code to demonstrate the use of agents\nconfigured in Agent Lab in watsonx.ai. It introduces Python API commands\nfor authentication using API key and invoking a LangGraph agent with a watsonx chat model.\n\n**Note:** Notebook code generated using Agent Lab will execute successfully.\nIf code is modified or reordered, there is no guarantee it will successfully execute.\nFor details, see: <a href=\"/docs/content/wsj/analyze-data/fm-prompt-save.html?context=wx\" target=\"_blank\">Saving your work in Agent Lab as a notebook.</a>\n\nSome familiarity with Python is helpful. This notebook uses Python 3.11.\n\n## Notebook goals\nThe learning goals of this notebook are:\n\n* Defining a Python function for obtaining credentials from the IBM Cloud personal API key\n* Creating an agent with a set of tools using a specified model and parameters\n* Invoking the agent to generate a response \n\n# Setup"}, {"metadata": {}, "cell_type": "code", "source": "# import dependencies\nfrom langchain_ibm import ChatWatsonx\nfrom ibm_watsonx_ai import APIClient\nfrom langchain_core.messages import AIMessage, HumanMessage\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom langgraph.prebuilt import create_react_agent\nfrom ibm_watsonx_ai.foundation_models.utils import Tool, Toolkit\nimport json\nimport requests", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## watsonx API connection\nThis cell defines the credentials required to work with watsonx API for Foundation\nModel inferencing.\n\n**Action:** Provide the IBM Cloud personal API key. For details, see\n<a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\">documentation</a>.\n"}, {"metadata": {}, "cell_type": "code", "source": "import os\nimport getpass\n\ndef get_credentials():\n\treturn {\n\t\t\"url\" : \"https://au-syd.ml.cloud.ibm.com\",\n\t\t\"apikey\" : getpass.getpass(\"Please enter your api key (hit enter): \")\n\t}\n\ndef get_bearer_token():\n    url = \"https://iam.cloud.ibm.com/identity/token\"\n    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n    data = f\"grant_type=urn:ibm:params:oauth:grant-type:apikey&apikey={credentials['apikey']}\"\n\n    response = requests.post(url, headers=headers, data=data)\n    return response.json().get(\"access_token\")\n\ncredentials = get_credentials()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Using the agent\nThese cells demonstrate how to create and invoke the agent\nwith the selected models, tools, and parameters.\n\n## Defining the model id\nWe need to specify model id that will be used for inferencing:"}, {"metadata": {}, "cell_type": "code", "source": "model_id = \"meta-llama/llama-3-2-11b-vision-instruct\"", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Defining the model parameters\nWe need to provide a set of model parameters that will influence the\nresult:"}, {"metadata": {}, "cell_type": "code", "source": "parameters = {\n    \"frequency_penalty\": 0,\n    \"max_tokens\": 2000,\n    \"presence_penalty\": 0,\n    \"temperature\": 0,\n    \"top_p\": 1\n}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Defining the project id or space id\nThe API requires project id or space id that provides the context for the call. We will obtain\nthe id from the project or space in which this notebook runs:"}, {"metadata": {}, "cell_type": "code", "source": "project_id = os.getenv(\"PROJECT_ID\")\nspace_id = os.getenv(\"SPACE_ID\")\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Creating the agent\nWe need to create the agent using the properties we defined so far:"}, {"metadata": {}, "cell_type": "code", "source": "client = APIClient(credentials=credentials, project_id=project_id, space_id=space_id)\n\n# Create the chat model\ndef create_chat_model():\n    chat_model = ChatWatsonx(\n        model_id=model_id,\n        url=credentials[\"url\"],\n        space_id=space_id,\n        project_id=project_id,\n        params=parameters,\n        watsonx_client=client,\n    )\n    return chat_model", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watsonx_ai.deployments import RuntimeContext\n\ncontext = RuntimeContext(api_client=client)\n\n\nvector_index_id = \"60f79086-f9fa-4049-bbe2-97a8e50d4294\"\n\ndef create_rag_tool(vector_index_id, api_client):\n    config = {\n        \"vectorIndexId\": vector_index_id,\n        \"projectId\": project_id\n    }\n\n    tool_description = \"Search information in documents to provide context to a user query. Useful when asked to ground the answer in specific knowledge about 61892e12-3a4b-46cc-9e34-c2ddbd1806e3_intents\"\n    \n    return create_utility_agent_tool(\"RAGQuery\", config, api_client, tool_description=tool_description)\n\n\n\ndef create_utility_agent_tool(tool_name, params, api_client, **kwargs):\n    from langchain_core.tools import StructuredTool\n    utility_agent_tool = Toolkit(\n        api_client=api_client\n    ).get_tool(tool_name)\n\n    tool_description = utility_agent_tool.get(\"description\")\n\n    if (kwargs.get(\"tool_description\")):\n        tool_description = kwargs.get(\"tool_description\")\n    elif (utility_agent_tool.get(\"agent_description\")):\n        tool_description = utility_agent_tool.get(\"agent_description\")\n    \n    tool_schema = utility_agent_tool.get(\"input_schema\")\n    if (tool_schema == None):\n        tool_schema = {\n            \"type\": \"object\",\n            \"additionalProperties\": False,\n            \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n            \"properties\": {\n                \"input\": {\n                    \"description\": \"input for the tool\",\n                    \"type\": \"string\"\n                }\n            }\n        }\n    \n    def run_tool(**tool_input):\n        query = tool_input\n        if (utility_agent_tool.get(\"input_schema\") == None):\n            query = tool_input.get(\"input\")\n\n        results = utility_agent_tool.run(\n            input=query,\n            config=params\n        )\n        \n        return results.get(\"output\")\n    \n    return StructuredTool(\n        name=tool_name,\n        description = tool_description,\n        func=run_tool,\n        args_schema=tool_schema\n    )\n\n\ndef create_custom_tool(tool_name, tool_description, tool_code, tool_schema, tool_params):\n    from langchain_core.tools import StructuredTool\n    import ast\n\n    def call_tool(**kwargs):\n        tree = ast.parse(tool_code, mode=\"exec\")\n        custom_tool_functions = [ x for x in tree.body if isinstance(x, ast.FunctionDef) ]\n        function_name = custom_tool_functions[0].name\n        compiled_code = compile(tree, 'custom_tool', 'exec')\n        namespace = tool_params if tool_params else {}\n        exec(compiled_code, namespace)\n        return namespace[function_name](**kwargs)\n        \n    tool = StructuredTool(\n        name=tool_name,\n        description = tool_description,\n        func=call_tool,\n        args_schema=tool_schema\n    )\n    return tool\n\ndef create_custom_tools():\n    custom_tools = []\n\n\ndef create_tools(context):\n    tools = []\n    tools.append(create_rag_tool(vector_index_id, client))\n    \n    config = None\n    tools.append(create_utility_agent_tool(\"GoogleSearch\", config, client))\n    config = {\n    }\n    tools.append(create_utility_agent_tool(\"DuckDuckGo\", config, client))\n    config = {\n        \"maxResults\": 5\n    }\n    tools.append(create_utility_agent_tool(\"Wikipedia\", config, client))\n\n    return tools", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def create_agent(context):\n    # Initialize the agent\n    chat_model = create_chat_model()\n    tools = create_tools(context)\n\n    memory = MemorySaver()\n    instructions = \"\"\"# General Behavior Guidelines\n\n- You are an AI assistant that provides accurate, safe, and user-friendly information.\n- Follow these rules for all interactions unless overridden by agent-specific instructions.\n\n## 1. Greeting & Conversation Etiquette\n- Always greet warmly at the start of the conversation.\n- Maintain a friendly, helpful, and respectful tone.\n- Encourage the user to share more details for better recommendations.\n- If the user returns after a previous conversation, acknowledge them and, if possible, remember their preferences.\n\n## 2. Tool Usage\n- Use tools like Watsonx.ai Prompt Lab, JSON lookups, or integrated APIs for generating responses.\n- Use markdown syntax for formatting code snippets, links, JSON, tables, images, or files.\n- Any HTML tags must be wrapped in block quotes, for example:\n  ```<html>```\n- When returning code blocks, specify the programming language.\n- For calculations or structured lookups, always call the appropriate tool instead of manually computing.\n- If a tool fails, try a different tool or adjust the query before declaring the problem unsolvable.\n\n## 3. Image Handling\n- If a tool returns an IMAGE in the result, include it in your answer as Markdown.\n- Example:\n  Tool result: IMAGE({commonApiUrl}/wx/v1-beta/utility_agent_tools/cache/images/example.png)\n  Markdown to return:\n  ![Generated image]({commonApiUrl}/wx/v1-beta/utility_agent_tools/cache/images/example.png)\n\n## 4. Accuracy & Safety\n- Ensure all nutrition-related information is factually correct.\n- Never recommend foods containing allergens that the user has specified.\n- Avoid medical claims and suggest professional consultation for specific health conditions.\n- Only provide dietary recommendations that are safe for general audiences.\n\n## 5. Clarity & Structure\n- Use simple, understandable language suitable for all audiences.\n- Present meal plans and advice using bullet points or numbered lists.\n- Avoid long paragraphs; keep responses structured for easy reading.\n\n## 6. Personalization & Continuity\n- Always adapt responses based on the user's goals, dietary preferences, and allergies.\n- Remember previously provided preferences within the same conversation.\n- Offer alternatives if a suggested food item is not suitable for the user.\n\n## 7. Ethics & Respect\n- Be inclusive and culturally sensitive.\n- Avoid stereotypes and biased assumptions in meal planning.\n- Show empathy and encouragement in all responses.\n\n## 8. Engagement & Feedback\n- After giving a meal plan, ask if the user would like more options or adjustments.\n- Invite them to provide feedback for better personalization.\n- Keep the interaction two-way, not just one-sided advice.\n\nYou are Nutrition_Assistant, a smart, empathetic, and interactive AI-powered virtual nutritionist built using Watsonx.ai and IBM Watson Assistant. You specialize in generating personalized meal plans and providing nutritional guidance.\n\nYour main role is to interact with users conversationally, collect relevant health and lifestyle information, and generate customized recommendations. You should:\n\n1. Greeting & Conversation Start:\n   - When greeted, say: \n\\\"Hi, I am Watsonx.ai Nutrition Assistant. I can help you create a meal plan tailored to your needs. First, what is your primary health goal? For example, weight loss, muscle gain, or a balanced diet.\\\"\n   - If the user asks for help with nutrition or a meal plan, first ask:\n     \\\"Great! What is your primary health goal? For example, weight loss, muscle gain, or a balanced diet.\\\"\n   - After goal, ask:\n     \\\"Got it. Do you have any dietary preferences, like vegetarian, vegan, or non-vegetarian?\\\"\n- After they answer, ask:\n     \\\"Thanks! Do you have any allergies I should be aware of?\\\"\n   - Only after collecting these details, move on to generating the meal plan.\n\n\n2. Information Gathering:\n   - Collect the following details from the user:\n     - Health goal (e.g., weight loss, muscle gain, balanced diet, managing a medical condition)\n     - Dietary preference (e.g., vegetarian, vegan, non-vegetarian, spicy, sweet)\n     - Allergies (e.g., gluten, dairy, nuts, soy)\n     - Lifestyle/activity level (e.g., sedentary, moderately active, highly active)\n     - Optional: preferred cuisine or cultural food preferences\n\n3. Personalization Rules:\n   - Always avoid suggesting foods containing allergens provided by the user.\n   - Adjust meals to align with both dietary preferences and cultural background.\n   - Ensure recommendations are realistic and accessible for most households.\n\n4. Meal Plan Generation:\n   - Use Watsonx.ai Prompt Lab to create dynamic meal plans when user data is complete.\n   - Each meal plan should include:\n       - Breakfast\n       - Lunch\n       - Dinner\n       - Optional snacks\n       -suggestions(like exercises and dietary) (if relevant)\n   - Provide short explanations for why each meal is chosen, focusing on health benefits and relevance to the user's goal.\n   - Suggest alternative food swaps when possible.\n\n5. Multimodal Capability:\n   - Be prepared to interpret and use information from text, voice, and optionally food-related images (e.g., grocery labels, meal photos).\n\n6. Feedback & Adaptation:\n   - After presenting a meal plan, ask: \\\"Would you like me to adjust this plan or provide alternatives?\\\"\n   - If feedback is given, adjust recommendations accordingly.\n   - Maintain a friendly, encouraging tone throughout.\n\n7. Style & Tone:\n   - Be professional, empathetic, supportive, and motivating.\n   - Use simple, clear language without heavy technical jargon.\n   - Use emojis sparingly to keep the tone warm but not unprofessional.\n\n8. Safety:\n   - Avoid giving medical diagnoses or unsafe diet advice.\n   - For serious or specific health conditions, politely recommend consulting a certified healthcare professional.\n\"\"\"\n\n    agent = create_react_agent(chat_model, tools=tools, checkpointer=memory, state_modifier=instructions)\n\n    return agent", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Visualize the graph\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n\nImage(\n    create_agent(context).get_graph().draw_mermaid_png(\n        draw_method=MermaidDrawMethod.API,\n    )\n)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Invoking the agent\nLet us now use the created agent, pair it with the input, and generate the response to your question:\n"}, {"metadata": {}, "cell_type": "code", "source": "agent = create_agent(context)\n\ndef convert_messages(messages):\n    converted_messages = []\n    for message in messages:\n        if (message[\"role\"] == \"user\"):\n            converted_messages.append(HumanMessage(content=message[\"content\"]))\n        elif (message[\"role\"] == \"assistant\"):\n            converted_messages.append(AIMessage(content=message[\"content\"]))\n    return converted_messages\n\nquestion = input(\"Question: \")\n\nmessages = [{\n    \"role\": \"user\",\n    \"content\": question\n}]\n\ngenerated_response = agent.invoke(\n    { \"messages\": convert_messages(messages) },\n    { \"configurable\": { \"thread_id\": \"42\" } }\n)\n\nprint_full_response = False\n\nif (print_full_response):\n    print(generated_response)\nelse:\n    result = generated_response[\"messages\"][-1].content\n    print(f\"Agent: {result}\")\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Next steps\nYou successfully completed this notebook! You learned how to use\nwatsonx.ai inferencing SDK to generate response from the foundation model\nbased on the provided input, model id and model parameters. Check out the\nofficial watsonx.ai site for more samples, tutorials, documentation, how-tos, and blog posts.\n\n<a id=\"copyrights\"></a>\n### Copyrights\n\nLicensed Materials - Copyright \u00a9 2024 IBM. This notebook and its source code are released under the terms of the ILAN License.\nUse, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n\n**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for watsonx.ai Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for watsonx.ai Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n\nBy downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"https://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\" target=\"_blank\">License Terms</a>  "}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}}, "nbformat": 4, "nbformat_minor": 0}